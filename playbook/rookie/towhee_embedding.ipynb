{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create image embeddings with Towhee\n",
    "\n",
    "We use the [towhee library](https://github.com/towhee-io/towhee) to create an embedding for a an image dataset. \n",
    "\n",
    "More information about this play can be found in the Spotlight documentation: [Create image embeddings with the towhee library](https://renumics.com/docs/playbook/towhee-embedding)\n",
    "\n",
    "For more data-centric AI workflows, check out our [Awesome Open Data-centric AI](https://github.com/Renumics/awesome-open-data-centric-ai) list on Github."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tldr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Install required packages with PIP\n",
    "!pip install renumics-spotlight towhee datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Play as copy-n-paste functions\n",
    "\n",
    "import datasets\n",
    "from towhee import pipeline, DataCollection\n",
    "from renumics import spotlight\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def towhee_embedding(df, modelname='towhee/image-embedding-swin-base-patch4-window7-224', image_name='image'):\n",
    "    dc = DataCollection(df[image_name])\n",
    "    embedding_pipeline = pipeline(modelname)\n",
    "    dc_embedding = dc.map(embedding_pipeline)\n",
    "    \n",
    "    \n",
    "    df_emb = pd.DataFrame()\n",
    "    df_emb['embedding']=dc_embedding.to_list()\n",
    "\n",
    "    return df_emb\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-step example on CIFAR-100\n",
    "\n",
    "### Load CIFAR-100 from Huggingface hub and convert it to Pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.load_dataset(\"renumics/cifar100-enriched\", split=\"train\")\n",
    "df = dataset.to_pandas()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute embedding with vision transformer from towhee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_emb=towhee_embedding(df, modelname='towhee/image-embedding-swin-base-patch4-window7-224')\n",
    "df = pd.concat([df, df_emb], axis=1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reduce embeddings for faster visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "import numpy as np\n",
    "embeddings = np.stack(df['embedding'].to_numpy())\n",
    "reducer = umap.UMAP()\n",
    "reduced_embedding = reducer.fit_transform(embeddings)\n",
    "df['embedding_reduced'] = np.array(reduced_embedding).tolist()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform EDA with Spotlight\n",
    "\n",
    "> ⚠️ Running Spotlight in Colab currently has severe limitations (slow, no similarity map, no layouts) due to Colab restrictions (e.g. no websocket support). Run the notebook locally for the full Spotlight experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_show = df.drop(columns=['embedding', 'probabilities'])\n",
    "\n",
    "# handle google colab differently\n",
    "import sys\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    #visualize subset in Google Colab\n",
    "    port=50123\n",
    "    spotlight.show(df_show[:10000], port=port, dtype={\"image\": spotlight.Image, \"embedding_reduced\": spotlight.Embedding})\n",
    "  \n",
    "    from google.colab.output import eval_js  # type: ignore\n",
    "    print(str(eval_js(f\"google.colab.kernel.proxyPort({port}, {{'cache': true}})\")))\n",
    "\n",
    "else:\n",
    "    spotlight.show(df_show, dtype={\"image\": spotlight.Image, \"embedding_reduced\": spotlight.Embedding})"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a0712b5d67739eb35ad63a27edd5fddd52f439fecfdecbb3b06a7c473af2eb31"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
