{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation: Fine-tuning\n",
    "\n",
    "Results are \n",
    "- folders with checkpoints of the fine-tuned model that can be use to create embedidngs for each training step.\n",
    "- a csv file `log.csv` containing loss values for each training step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers[torch] in /home/markus/spotlight/.venv/lib/python3.10/site-packages (4.30.2)\n",
      "Requirement already satisfied: datasets in /home/markus/spotlight/.venv/lib/python3.10/site-packages (2.13.1)\n",
      "Requirement already satisfied: pandas in /home/markus/spotlight/.venv/lib/python3.10/site-packages (2.0.3)\n",
      "Requirement already satisfied: pillow in /home/markus/spotlight/.venv/lib/python3.10/site-packages (10.0.0)\n",
      "Requirement already satisfied: cleanlab in /home/markus/spotlight/.venv/lib/python3.10/site-packages (2.4.0)\n",
      "Requirement already satisfied: scipy in /home/markus/spotlight/.venv/lib/python3.10/site-packages (1.11.1)\n",
      "Requirement already satisfied: matplotlib in /home/markus/spotlight/.venv/lib/python3.10/site-packages (3.7.2)\n",
      "Requirement already satisfied: imageio in /home/markus/spotlight/.venv/lib/python3.10/site-packages (2.31.1)\n",
      "Requirement already satisfied: renumics-spotlight in /home/markus/spotlight/.venv/lib/python3.10/site-packages (1.3.0rc3.post70+9e859d5)\n",
      "Requirement already satisfied: filelock in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from transformers[torch]) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from transformers[torch]) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from transformers[torch]) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from transformers[torch]) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from transformers[torch]) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from transformers[torch]) (2023.6.3)\n",
      "Requirement already satisfied: requests in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from transformers[torch]) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from transformers[torch]) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from transformers[torch]) (4.65.0)\n",
      "Requirement already satisfied: torch!=1.12.0,>=1.9 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from transformers[torch]) (2.0.1)\n",
      "Requirement already satisfied: accelerate>=0.20.2 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from transformers[torch]) (0.20.3)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from datasets) (12.0.1)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: xxhash in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from datasets) (2023.6.0)\n",
      "Requirement already satisfied: aiohttp in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from datasets) (3.8.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scikit-learn>=1.0 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from cleanlab) (1.3.0)\n",
      "Requirement already satisfied: termcolor>=2.0.0 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from cleanlab) (2.3.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from matplotlib) (4.41.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: aiofiles in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (23.1.0)\n",
      "Requirement already satisfied: appdirs in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (1.4.4)\n",
      "Requirement already satisfied: av in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (10.0.0)\n",
      "Requirement already satisfied: cleanvision in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (0.3.1)\n",
      "Requirement already satisfied: click in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (8.1.4)\n",
      "Requirement already satisfied: databases[aiosqlite] in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (0.7.0)\n",
      "Requirement already satisfied: diskcache in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (5.6.1)\n",
      "Requirement already satisfied: fastapi>=0.65.2 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (0.100.0)\n",
      "Requirement already satisfied: filetype in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (1.2.0)\n",
      "Requirement already satisfied: h5py>3.0 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (3.9.0)\n",
      "Requirement already satisfied: httptools in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (0.6.0)\n",
      "Requirement already satisfied: imagecodecs in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (2023.7.10)\n",
      "Requirement already satisfied: importlib_resources<5.8.0 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (5.7.1)\n",
      "Requirement already satisfied: ipywidgets in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (8.0.7)\n",
      "Requirement already satisfied: jinja2 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (3.1.2)\n",
      "Requirement already satisfied: loguru in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (0.7.0)\n",
      "Requirement already satisfied: networkx in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (3.1)\n",
      "Requirement already satisfied: notebook in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (6.5.4)\n",
      "Requirement already satisfied: orjson in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (3.9.2)\n",
      "Requirement already satisfied: prettytable in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (3.8.0)\n",
      "Requirement already satisfied: py-machineid in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (0.4.1)\n",
      "Requirement already satisfied: pycatch22 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (0.4.2)\n",
      "Requirement already satisfied: pydantic<2.0.0 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (1.10.11)\n",
      "Requirement already satisfied: pygltflib>=1.15.1 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (1.15.6)\n",
      "Requirement already satisfied: rsa in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (4.9)\n",
      "Requirement already satisfied: scikit-image in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (0.21.0)\n",
      "Requirement already satisfied: setuptools in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (65.5.0)\n",
      "Requirement already satisfied: toml in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (0.10.2)\n",
      "Requirement already satisfied: trimesh in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (3.22.3)\n",
      "Requirement already satisfied: typing-extensions in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (4.7.1)\n",
      "Requirement already satisfied: umap-learn in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (0.5.3)\n",
      "Requirement already satisfied: uvicorn in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (0.22.0)\n",
      "Requirement already satisfied: uvloop>=0.17.0 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (0.17.0)\n",
      "Requirement already satisfied: validators in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (0.20.0)\n",
      "Requirement already satisfied: websockets in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from renumics-spotlight) (11.0.3)\n",
      "Requirement already satisfied: psutil in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from accelerate>=0.20.2->transformers[torch]) (5.9.5)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from fastapi>=0.65.2->renumics-spotlight) (0.27.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (3.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: dataclasses-json>=0.0.25 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from pygltflib>=1.15.1->renumics-spotlight) (0.5.9)\n",
      "Requirement already satisfied: deprecated in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from pygltflib>=1.15.1->renumics-spotlight) (1.2.14)\n",
      "Requirement already satisfied: six>=1.5 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from requests->transformers[torch]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from requests->transformers[torch]) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from requests->transformers[torch]) (2023.5.7)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from scikit-learn>=1.0->cleanlab) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from scikit-learn>=1.0->cleanlab) (3.1.0)\n",
      "Requirement already satisfied: sympy in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (1.12)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from torch!=1.12.0,>=1.9->transformers[torch]) (2.0.0)\n",
      "Requirement already satisfied: wheel in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch!=1.12.0,>=1.9->transformers[torch]) (0.40.0)\n",
      "Requirement already satisfied: cmake in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]) (3.26.4)\n",
      "Requirement already satisfied: lit in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from triton==2.0.0->torch!=1.12.0,>=1.9->transformers[torch]) (16.0.6)\n",
      "Requirement already satisfied: tabulate>=0.8.3 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from cleanvision->renumics-spotlight) (0.9.0)\n",
      "Requirement already satisfied: imagehash>=4.2.0 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from cleanvision->renumics-spotlight) (4.3.1)\n",
      "Requirement already satisfied: sqlalchemy<1.5,>=1.4.42 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from databases[aiosqlite]->renumics-spotlight) (1.4.49)\n",
      "Requirement already satisfied: aiosqlite in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from databases[aiosqlite]->renumics-spotlight) (0.19.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from ipywidgets->renumics-spotlight) (6.24.0)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from ipywidgets->renumics-spotlight) (8.14.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from ipywidgets->renumics-spotlight) (5.9.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.7 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from ipywidgets->renumics-spotlight) (4.0.8)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.7 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from ipywidgets->renumics-spotlight) (3.0.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from jinja2->renumics-spotlight) (2.1.3)\n",
      "Requirement already satisfied: tornado>=6.1 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from notebook->renumics-spotlight) (6.3.2)\n",
      "Requirement already satisfied: pyzmq>=17 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from notebook->renumics-spotlight) (25.1.0)\n",
      "Requirement already satisfied: argon2-cffi in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from notebook->renumics-spotlight) (21.3.0)\n",
      "Requirement already satisfied: jupyter-core>=4.6.1 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from notebook->renumics-spotlight) (5.3.1)\n",
      "Requirement already satisfied: jupyter-client>=5.3.4 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from notebook->renumics-spotlight) (8.3.0)\n",
      "Requirement already satisfied: ipython-genutils in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from notebook->renumics-spotlight) (0.2.0)\n",
      "Requirement already satisfied: nbformat in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from notebook->renumics-spotlight) (5.9.1)\n",
      "Requirement already satisfied: nbconvert>=5 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from notebook->renumics-spotlight) (7.6.0)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from notebook->renumics-spotlight) (1.5.6)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from notebook->renumics-spotlight) (1.8.2)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from notebook->renumics-spotlight) (0.17.1)\n",
      "Requirement already satisfied: prometheus-client in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from notebook->renumics-spotlight) (0.17.1)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from notebook->renumics-spotlight) (1.0.0)\n",
      "Requirement already satisfied: wcwidth in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from prettytable->renumics-spotlight) (0.2.6)\n",
      "Requirement already satisfied: winregistry in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from py-machineid->renumics-spotlight) (1.1.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from rsa->renumics-spotlight) (0.5.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from scikit-image->renumics-spotlight) (2023.7.10)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from scikit-image->renumics-spotlight) (1.4.1)\n",
      "Requirement already satisfied: lazy_loader>=0.2 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from scikit-image->renumics-spotlight) (0.3)\n",
      "Requirement already satisfied: numba>=0.49 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from umap-learn->renumics-spotlight) (0.57.1)\n",
      "Requirement already satisfied: pynndescent>=0.5 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from umap-learn->renumics-spotlight) (0.5.10)\n",
      "Requirement already satisfied: h11>=0.8 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from uvicorn->renumics-spotlight) (0.14.0)\n",
      "Requirement already satisfied: decorator>=3.4.0 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from validators->renumics-spotlight) (5.1.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from dataclasses-json>=0.0.25->pygltflib>=1.15.1->renumics-spotlight) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from dataclasses-json>=0.0.25->pygltflib>=1.15.1->renumics-spotlight) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from dataclasses-json>=0.0.25->pygltflib>=1.15.1->renumics-spotlight) (0.9.0)\n",
      "Requirement already satisfied: comm>=0.1.1 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets->renumics-spotlight) (0.1.3)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets->renumics-spotlight) (1.6.7)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from ipykernel>=4.5.1->ipywidgets->renumics-spotlight) (0.1.6)\n",
      "Requirement already satisfied: backcall in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->renumics-spotlight) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->renumics-spotlight) (0.18.2)\n",
      "Requirement already satisfied: pickleshare in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->renumics-spotlight) (0.7.5)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->renumics-spotlight) (3.0.39)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->renumics-spotlight) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->renumics-spotlight) (0.6.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets->renumics-spotlight) (4.8.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from jupyter-core>=4.6.1->notebook->renumics-spotlight) (3.8.1)\n",
      "Requirement already satisfied: jupyter-server>=1.8 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook->renumics-spotlight) (2.7.0)\n",
      "Requirement already satisfied: notebook-shim>=0.2.3 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook->renumics-spotlight) (0.2.3)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from nbconvert>=5->notebook->renumics-spotlight) (4.12.2)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from nbconvert>=5->notebook->renumics-spotlight) (6.0.0)\n",
      "Requirement already satisfied: defusedxml in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from nbconvert>=5->notebook->renumics-spotlight) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from nbconvert>=5->notebook->renumics-spotlight) (0.2.2)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from nbconvert>=5->notebook->renumics-spotlight) (3.0.1)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from nbconvert>=5->notebook->renumics-spotlight) (0.8.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from nbconvert>=5->notebook->renumics-spotlight) (1.5.0)\n",
      "Requirement already satisfied: tinycss2 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from nbconvert>=5->notebook->renumics-spotlight) (1.2.1)\n",
      "Requirement already satisfied: fastjsonschema in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from nbformat->notebook->renumics-spotlight) (2.17.1)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from nbformat->notebook->renumics-spotlight) (4.18.2)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from numba>=0.49->umap-learn->renumics-spotlight) (0.40.1)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from sqlalchemy<1.5,>=1.4.42->databases[aiosqlite]->renumics-spotlight) (2.0.2)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from starlette<0.28.0,>=0.27.0->fastapi>=0.65.2->renumics-spotlight) (3.7.1)\n",
      "Requirement already satisfied: ptyprocess in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from terminado>=0.8.3->notebook->renumics-spotlight) (0.7.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from argon2-cffi->notebook->renumics-spotlight) (21.2.0)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from deprecated->pygltflib>=1.15.1->renumics-spotlight) (1.15.0)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from sympy->torch!=1.12.0,>=1.9->transformers[torch]) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi>=0.65.2->renumics-spotlight) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi>=0.65.2->renumics-spotlight) (1.1.2)\n",
      "Requirement already satisfied: webencodings in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from bleach!=5.0.0->nbconvert>=5->notebook->renumics-spotlight) (0.5.1)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets->renumics-spotlight) (0.8.3)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook->renumics-spotlight) (2023.6.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook->renumics-spotlight) (0.29.1)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook->renumics-spotlight) (0.8.10)\n",
      "Requirement already satisfied: jupyter-events>=0.6.0 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->renumics-spotlight) (0.6.3)\n",
      "Requirement already satisfied: jupyter-server-terminals in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->renumics-spotlight) (0.4.4)\n",
      "Requirement already satisfied: overrides in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->renumics-spotlight) (7.3.1)\n",
      "Requirement already satisfied: websocket-client in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from jupyter-server>=1.8->nbclassic>=0.4.7->notebook->renumics-spotlight) (1.6.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from typing-inspect>=0.4.0->dataclasses-json>=0.0.25->pygltflib>=1.15.1->renumics-spotlight) (1.0.0)\n",
      "Requirement already satisfied: cffi>=1.0.1 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from argon2-cffi-bindings->argon2-cffi->notebook->renumics-spotlight) (1.15.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from beautifulsoup4->nbconvert>=5->notebook->renumics-spotlight) (2.4.1)\n",
      "Requirement already satisfied: executing>=1.2.0 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->renumics-spotlight) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->renumics-spotlight) (2.2.1)\n",
      "Requirement already satisfied: pure-eval in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets->renumics-spotlight) (0.2.2)\n",
      "Requirement already satisfied: pycparser in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->renumics-spotlight) (2.21)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->renumics-spotlight) (2.0.7)\n",
      "Requirement already satisfied: rfc3339-validator in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->renumics-spotlight) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from jupyter-events>=0.6.0->jupyter-server>=1.8->nbclassic>=0.4.7->notebook->renumics-spotlight) (0.1.1)\n",
      "Requirement already satisfied: fqdn in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook->renumics-spotlight) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook->renumics-spotlight) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook->renumics-spotlight) (2.4)\n",
      "Requirement already satisfied: uri-template in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook->renumics-spotlight) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=1.11 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from jsonschema>=2.6->nbformat->notebook->renumics-spotlight) (1.13)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /home/markus/spotlight/.venv/lib/python3.10/site-packages (from isoduration->jsonschema>=2.6->nbformat->notebook->renumics-spotlight) (1.2.3)\n"
     ]
    }
   ],
   "source": [
    "# rewrite based https://huggingface.co/docs/transformers/tasks/image_classification\n",
    "# Install required libraries\n",
    "!pip install transformers[torch] datasets  pandas pillow cleanlab scipy matplotlib imageio renumics-spotlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cifar10 (/home/markus/.cache/huggingface/datasets/cifar10/plain_text/1.0.0/447d6ec4733dddd1ce3bb577c7166b986eaa4c538dcd9e805ba61f35674a9de4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9a79a1a16b44554a8b2e56fb3671c06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load cifar10 dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"cifar10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the label2id and id2label dicts mapping labels to index values and vice versa.\n",
    "labels = ds[\"train\"].features[\"label\"].names\n",
    "label2id, id2label = dict(), dict()\n",
    "for i, label in enumerate(labels):\n",
    "    label2id[label] = str(i)\n",
    "    id2label[str(i)] = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "396b1236433c4b3788214e33f659e835",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)rocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3b3b3cc9e804938ab3848de4be3900c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load an image preprocessor for the model. This will resize the images to the correct size for the model, and also apply any other transformations that are necessary.\n",
    "from transformers import AutoImageProcessor\n",
    "\n",
    "checkpoint = \"google/vit-base-patch16-224-in21k\"\n",
    "image_processor = AutoImageProcessor.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a list of PIL images and turn them to pixel values\n",
    "\n",
    "\n",
    "def transform(example_batch):\n",
    "    inputs = image_processor(\n",
    "        [x.convert(\"RGB\") for x in example_batch[\"img\"]], return_tensors=\"pt\"\n",
    "    )\n",
    "    inputs[\"label\"] = example_batch[\"label\"]\n",
    "    return inputs\n",
    "\n",
    "\n",
    "# Apply transform on the dataset\n",
    "prepared_ds = ds.with_transform(transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a data collator to create batches\n",
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba84a1c79ca41d59c287c43bd8695fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading pytorch_model.bin:   0%|          | 0.00/346M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at google/vit-base-patch16-224-in21k were not used when initializing ViTForImageClassification: ['pooler.dense.weight', 'pooler.dense.bias']\n",
      "- This IS expected if you are initializing ViTForImageClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ViTForImageClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-base-patch16-224-in21k and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the pre-trained model with AutoModelForImageClassification. Specify number of labels and the label mappings.\n",
    "from transformers import AutoModelForImageClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    checkpoint,\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use an additional callback to write the loss values of time into a .csv file.\n",
    "from transformers import TrainerCallback\n",
    "\n",
    "\n",
    "class PrinterCallback(TrainerCallback):\n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        _ = logs.pop(\"total_flos\", None)\n",
    "        if state.is_local_process_zero:\n",
    "            if len(logs) == 3:  # skip last row\n",
    "                with open(\"log.csv\", \"a\") as f:\n",
    "                    f.write(\",\".join(map(str, logs.values())) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup training paramter: Choose a low save_step interval for many frame for the video later\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "batch_size = 8\n",
    "# Defining training arguments (set push_to_hub to false if you don't want to upload it to HuggingFace's model hub)\n",
    "training_args = TrainingArguments(\n",
    "    f\"vit-base-patch16-224-in21k-ft-cifar10_highres_train\",\n",
    "    remove_unused_columns=False,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=100,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=20,  # the movie will be created by checkpoint save in this interval. Lower values increase the number of frames\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    gradient_accumulation_steps=4,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=0.04,  # use 0.04 for testing with a few frames. Use highe values for long movies\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=20,\n",
    "    load_best_model_at_end=False,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/markus/spotlight/.venv/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b3e77d5f8cb416eb764848a83b345cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 1.95 GiB total capacity; 1.24 GiB already allocated; 9.75 MiB free; 1.36 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 16\u001b[0m\n\u001b[1;32m      5\u001b[0m trainer \u001b[39m=\u001b[39m Trainer(\n\u001b[1;32m      6\u001b[0m     model\u001b[39m=\u001b[39mmodel,\n\u001b[1;32m      7\u001b[0m     args\u001b[39m=\u001b[39mtraining_args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     callbacks\u001b[39m=\u001b[39m[PrinterCallback],\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[39m# Train and save results\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m train_results \u001b[39m=\u001b[39m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/spotlight/.venv/lib/python3.10/site-packages/transformers/trainer.py:1645\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1640\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\n\u001b[1;32m   1642\u001b[0m inner_training_loop \u001b[39m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1643\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_inner_training_loop, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_train_batch_size, args\u001b[39m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1644\u001b[0m )\n\u001b[0;32m-> 1645\u001b[0m \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1646\u001b[0m     args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1647\u001b[0m     resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1648\u001b[0m     trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1649\u001b[0m     ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1650\u001b[0m )\n",
      "File \u001b[0;32m~/spotlight/.venv/lib/python3.10/site-packages/transformers/trainer.py:1938\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1935\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_begin(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[1;32m   1937\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1938\u001b[0m     tr_loss_step \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_step(model, inputs)\n\u001b[1;32m   1940\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1941\u001b[0m     args\u001b[39m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1942\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1943\u001b[0m     \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39misnan(tr_loss_step) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1944\u001b[0m ):\n\u001b[1;32m   1945\u001b[0m     \u001b[39m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1946\u001b[0m     tr_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tr_loss \u001b[39m/\u001b[39m (\u001b[39m1\u001b[39m \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mglobal_step \u001b[39m-\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[0;32m~/spotlight/.venv/lib/python3.10/site-packages/transformers/trainer.py:2752\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2734\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2735\u001b[0m \u001b[39mPerform a training step on a batch of inputs.\u001b[39;00m\n\u001b[1;32m   2736\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2749\u001b[0m \u001b[39m    `torch.Tensor`: The tensor with training loss on this batch.\u001b[39;00m\n\u001b[1;32m   2750\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2751\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[0;32m-> 2752\u001b[0m inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_inputs(inputs)\n\u001b[1;32m   2754\u001b[0m \u001b[39mif\u001b[39;00m is_sagemaker_mp_enabled():\n\u001b[1;32m   2755\u001b[0m     loss_mb \u001b[39m=\u001b[39m smp_forward_backward(model, inputs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mgradient_accumulation_steps)\n",
      "File \u001b[0;32m~/spotlight/.venv/lib/python3.10/site-packages/transformers/trainer.py:2697\u001b[0m, in \u001b[0;36mTrainer._prepare_inputs\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2692\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_prepare_inputs\u001b[39m(\u001b[39mself\u001b[39m, inputs: Dict[\u001b[39mstr\u001b[39m, Union[torch\u001b[39m.\u001b[39mTensor, Any]]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Union[torch\u001b[39m.\u001b[39mTensor, Any]]:\n\u001b[1;32m   2693\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2694\u001b[0m \u001b[39m    Prepare `inputs` before feeding them to the model, converting them to tensors if they are not already and\u001b[39;00m\n\u001b[1;32m   2695\u001b[0m \u001b[39m    handling potential state.\u001b[39;00m\n\u001b[1;32m   2696\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2697\u001b[0m     inputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_input(inputs)\n\u001b[1;32m   2698\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(inputs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   2699\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   2700\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe batch received was empty, your model won\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt be able to train on it. Double-check that your \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2701\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtraining dataset contains keys expected by the model: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m,\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_signature_columns)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2702\u001b[0m         )\n",
      "File \u001b[0;32m~/spotlight/.venv/lib/python3.10/site-packages/transformers/trainer.py:2679\u001b[0m, in \u001b[0;36mTrainer._prepare_input\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2675\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2676\u001b[0m \u001b[39mPrepares one `data` before feeding it to the model, be it a tensor or a nested list/dictionary of tensors.\u001b[39;00m\n\u001b[1;32m   2677\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, Mapping):\n\u001b[0;32m-> 2679\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(data)({k: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_input(v) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mitems()})\n\u001b[1;32m   2680\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, (\u001b[39mtuple\u001b[39m, \u001b[39mlist\u001b[39m)):\n\u001b[1;32m   2681\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(data)(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_input(v) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m data)\n",
      "File \u001b[0;32m~/spotlight/.venv/lib/python3.10/site-packages/transformers/trainer.py:2679\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2675\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2676\u001b[0m \u001b[39mPrepares one `data` before feeding it to the model, be it a tensor or a nested list/dictionary of tensors.\u001b[39;00m\n\u001b[1;32m   2677\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   2678\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, Mapping):\n\u001b[0;32m-> 2679\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(data)({k: \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_prepare_input(v) \u001b[39mfor\u001b[39;00m k, v \u001b[39min\u001b[39;00m data\u001b[39m.\u001b[39mitems()})\n\u001b[1;32m   2680\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(data, (\u001b[39mtuple\u001b[39m, \u001b[39mlist\u001b[39m)):\n\u001b[1;32m   2681\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mtype\u001b[39m(data)(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_prepare_input(v) \u001b[39mfor\u001b[39;00m v \u001b[39min\u001b[39;00m data)\n",
      "File \u001b[0;32m~/spotlight/.venv/lib/python3.10/site-packages/transformers/trainer.py:2689\u001b[0m, in \u001b[0;36mTrainer._prepare_input\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   2684\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_deepspeed_enabled \u001b[39mand\u001b[39;00m (torch\u001b[39m.\u001b[39mis_floating_point(data) \u001b[39mor\u001b[39;00m torch\u001b[39m.\u001b[39mis_complex(data)):\n\u001b[1;32m   2685\u001b[0m         \u001b[39m# NLP models inputs are int/uint and those get adjusted to the right dtype of the\u001b[39;00m\n\u001b[1;32m   2686\u001b[0m         \u001b[39m# embedding. Other models such as wav2vec2's inputs are already float and thus\u001b[39;00m\n\u001b[1;32m   2687\u001b[0m         \u001b[39m# may need special handling to match the dtypes of the model\u001b[39;00m\n\u001b[1;32m   2688\u001b[0m         kwargs\u001b[39m.\u001b[39mupdate({\u001b[39m\"\u001b[39m\u001b[39mdtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maccelerator\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mdeepspeed_plugin\u001b[39m.\u001b[39mhf_ds_config\u001b[39m.\u001b[39mdtype()})\n\u001b[0;32m-> 2689\u001b[0m     \u001b[39mreturn\u001b[39;00m data\u001b[39m.\u001b[39;49mto(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2690\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 1.95 GiB total capacity; 1.24 GiB already allocated; 9.75 MiB free; 1.36 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# Instantiate the Trainer object abd start the training\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=prepared_ds[\"train\"],\n",
    "    eval_dataset=prepared_ds[\"test\"],\n",
    "    tokenizer=image_processor,\n",
    "    callbacks=[PrinterCallback],\n",
    ")\n",
    "\n",
    "# Train and save results\n",
    "train_results = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation of the embedding\n",
    "\n",
    "Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions to create embeddings from an individual checkpoint\n",
    "# Play from https://renumics.com/next/docs/playbook/huggingface-embedding\n",
    "import datasets\n",
    "from transformers import AutoFeatureExtractor, AutoModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def extract_embeddings(model, feature_extractor, image_name=\"image\"):\n",
    "    \"\"\"Utility to compute embeddings.\"\"\"\n",
    "    device = model.device\n",
    "\n",
    "    def pp(batch):\n",
    "        images = batch[\"image\"]\n",
    "        inputs = feature_extractor(images=images, return_tensors=\"pt\").to(device)\n",
    "        embeddings = model(**inputs).last_hidden_state[:, 0].cpu()\n",
    "\n",
    "        return {\"embedding\": embeddings}\n",
    "\n",
    "    return pp\n",
    "\n",
    "\n",
    "def huggingface_embedding(\n",
    "    df,\n",
    "    image_name=\"image\",\n",
    "    inplace=False,\n",
    "    modelname=\"google/vit-base-patch16-224\",\n",
    "    batched=True,\n",
    "    batch_size=24,\n",
    "):\n",
    "    # initialize huggingface model\n",
    "    feature_extractor = AutoFeatureExtractor.from_pretrained(modelname)\n",
    "    model = AutoModel.from_pretrained(modelname, output_hidden_states=True)\n",
    "\n",
    "    # create huggingface dataset from df\n",
    "    dataset = datasets.Dataset.from_pandas(df).cast_column(image_name, datasets.Image())\n",
    "\n",
    "    # compute embedding\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    extract_fn = extract_embeddings(model.to(device), feature_extractor, image_name)\n",
    "    updated_dataset = dataset.map(extract_fn, batched=batched, batch_size=batch_size)\n",
    "\n",
    "    df_temp = updated_dataset.to_pandas()\n",
    "\n",
    "    if inplace:\n",
    "        df[\"embedding\"] = df_temp[\"embedding\"]\n",
    "        return\n",
    "\n",
    "    df_emb = pd.DataFrame()\n",
    "    df_emb[\"embedding\"] = df_temp[\"embedding\"]\n",
    "\n",
    "    return df_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset cifar10 (/home/markus/.cache/huggingface/datasets/cifar10/plain_text/1.0.0/447d6ec4733dddd1ce3bb577c7166b986eaa4c538dcd9e805ba61f35674a9de4)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c30a9dc5a454ce3a4d48c6c1033052f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Casting the dataset:   0%|          | 0/10000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load CIFAR-100 from Huggingface hub and convert it to Pandas dataframe\n",
    "import datasets\n",
    "\n",
    "ds = datasets.load_dataset(\"cifar10\", split=\"test\").prepare_for_task(\n",
    "    \"image-classification\"\n",
    ")\n",
    "df = ds.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'log.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Load loss from csv file into loss_df\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m loss_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39mlog.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m, names\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mloss\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mlearning_rate\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mepoch\u001b[39;49m\u001b[39m\"\u001b[39;49m])\n\u001b[1;32m      5\u001b[0m loss_df\n",
      "File \u001b[0;32m~/spotlight/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/spotlight/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/spotlight/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/spotlight/.venv/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/spotlight/.venv/lib/python3.10/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'log.csv'"
     ]
    }
   ],
   "source": [
    "# Load loss from csv file into loss_df\n",
    "import pandas as pd\n",
    "\n",
    "loss_df = pd.read_csv(\"log.csv\", names=[\"loss\", \"learning_rate\", \"epoch\"])\n",
    "loss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to get all available checkpoints as sorted folders\n",
    "import os\n",
    "import datasets\n",
    "import time\n",
    "\n",
    "\n",
    "def get_sorted_checkpoint_folders():\n",
    "    # list all subfolders of 'renumics/vit-base-patch16-224-in21k-ft-cifar10' that have checkpoint in the name\n",
    "    checkpoint_folders = [\n",
    "        x\n",
    "        for x in os.listdir(\"vit-base-patch16-224-in21k-ft-cifar10_highres_train\")\n",
    "        if \"checkpoint\" in x\n",
    "    ]\n",
    "\n",
    "    # sort the list of folders\n",
    "    sorted_checkpoint_folders = sorted(\n",
    "        checkpoint_folders, key=lambda x: int(x.split(\"-\")[-1])\n",
    "    )\n",
    "    sorted_checkpoint_folders = [\n",
    "        \"vit-base-patch16-224-in21k-ft-cifar10_highres_train\" + \"/\" + x\n",
    "        for x in sorted_checkpoint_folders\n",
    "    ]\n",
    "    return sorted_checkpoint_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'vit-base-patch16-224-in21k-ft-cifar10_highres_train'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# create embeddings with each checkpont and store them in the same folder\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfor\u001b[39;00m sorted_checkpoint_folder \u001b[39min\u001b[39;00m get_sorted_checkpoint_folders():\n\u001b[1;32m      3\u001b[0m     \u001b[39m# check if embedding already exists\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[39mif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mexists(sorted_checkpoint_folder \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/embedding.pkl\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m      5\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m, in \u001b[0;36mget_sorted_checkpoint_folders\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_sorted_checkpoint_folders\u001b[39m():\n\u001b[1;32m      8\u001b[0m     \u001b[39m# list all subfolders of 'renumics/vit-base-patch16-224-in21k-ft-cifar10' that have checkpoint in the name\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     checkpoint_folders \u001b[39m=\u001b[39m [\n\u001b[1;32m     10\u001b[0m         x\n\u001b[0;32m---> 11\u001b[0m         \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m os\u001b[39m.\u001b[39;49mlistdir(\u001b[39m\"\u001b[39;49m\u001b[39mvit-base-patch16-224-in21k-ft-cifar10_highres_train\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     12\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcheckpoint\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m x\n\u001b[1;32m     13\u001b[0m     ]\n\u001b[1;32m     15\u001b[0m     \u001b[39m# sort the list of folders\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     sorted_checkpoint_folders \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39m(\n\u001b[1;32m     17\u001b[0m         checkpoint_folders, key\u001b[39m=\u001b[39m\u001b[39mlambda\u001b[39;00m x: \u001b[39mint\u001b[39m(x\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m-\u001b[39m\u001b[39m\"\u001b[39m)[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m     18\u001b[0m     )\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'vit-base-patch16-224-in21k-ft-cifar10_highres_train'"
     ]
    }
   ],
   "source": [
    "# create embeddings with each checkpont and store them in the same folder\n",
    "for sorted_checkpoint_folder in get_sorted_checkpoint_folders():\n",
    "    # check if embedding already exists\n",
    "    if os.path.exists(sorted_checkpoint_folder + \"/embedding.pkl\"):\n",
    "        continue\n",
    "    embedding = huggingface_embedding(\n",
    "        df, modelname=sorted_checkpoint_folder, image_name=\"image\"\n",
    "    )[\"embedding\"]\n",
    "    # store in smae folder\n",
    "    embedding.to_pickle(sorted_checkpoint_folder + \"/embedding.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to extract outliers based on embeddings using cleanlab\n",
    "import io\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from cleanlab.outlier import OutOfDistribution\n",
    "\n",
    "\n",
    "def get_ood(sorted_checkpoint_folder, df):\n",
    "    embedding = pd.read_pickle(sorted_checkpoint_folder + \"/embedding.pkl\").to_list()\n",
    "    embedding_np = np.array(embedding)\n",
    "\n",
    "    ood = OutOfDistribution()\n",
    "    ood_train_feature_scores = ood.fit_score(features=embedding_np)\n",
    "    df[\"scores\"] = ood_train_feature_scores\n",
    "\n",
    "    # select row with the lowest 8 scores\n",
    "    df_ood = df.sort_values(by=[\"scores\"], ascending=True).head(8)\n",
    "    # load the 8 corresponding images\n",
    "    df_ood_images = [\n",
    "        (Image.open(io.BytesIO(x[\"bytes\"])).convert(\"RGB\"), l)\n",
    "        for x, l in df_ood[[\"image\", \"labels\"]].to_numpy()\n",
    "    ]\n",
    "    return df_ood_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function to generate a PCA, use procrustes to transfor the created points to given input if provied.\n",
    "# this can be used to flip, rotate and scale the points of the new frame on the old frame to stabalize the movie.\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial import procrustes\n",
    "\n",
    "\n",
    "def make_pca(sorted_checkpoint_folder, pca_np):\n",
    "    embedding = pd.read_pickle(sorted_checkpoint_folder + \"/embedding.pkl\").to_list()\n",
    "    embedding_np = np.array(embedding)\n",
    "    embedding_np_flat = embedding_np.reshape(-1, 768)\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_np_new = pca.fit_transform(embedding_np_flat)\n",
    "\n",
    "    if pca_np is None:\n",
    "        pca_np = pca_np_new\n",
    "\n",
    "    _, pca_np_new, disparity = procrustes(pca_np, pca_np_new)\n",
    "    pca_np = pca_np_new\n",
    "\n",
    "    # scale pca_np_new to be in range [-5, 5]\n",
    "    pca_np_disp = pca_np_new * 5 / np.max(np.abs(pca_np_new))\n",
    "    return pca_np_disp"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review in Spotlight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ds.to_pandas()\n",
    "first, last = get_sorted_checkpoint_folders()[0,-1]\n",
    "df_ood_images_first = get_ood(first, df)\n",
    "df_ood_images_last = get_ood(last, df)\n",
    "pca_np_disp_first = make_pca(first)\n",
    "pca_np_disp_last = make_pca(last, pca_np_disp_first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an image for each checkpoint and store it next to the checkpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import tqdm\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8, 8), dpi=200)\n",
    "all_labels = ds.to_pandas()[\"labels\"]\n",
    "pca_np_disp = None\n",
    "for i, sorted_checkpoint_folder in tqdm.tqdm(\n",
    "    enumerate(get_sorted_checkpoint_folders())\n",
    "):\n",
    "    df_ood_images = get_ood(sorted_checkpoint_folder, df)\n",
    "    pca_np_disp = make_pca(sorted_checkpoint_folder, pca_np_disp)\n",
    "\n",
    "    # prepare figure\n",
    "    fig.clf()\n",
    "    a0, a1 = fig.subplots(2, 1, gridspec_kw={\"height_ratios\": [5, 1], \"hspace\": 0.4})\n",
    "    _ = fig.suptitle(\n",
    "        \"Fine Tuning Training Step \" + str(i * 2) + \" of a Vision Transformer (ViT)\"\n",
    "    )\n",
    "\n",
    "    # setup subplot of pca points\n",
    "    a0.set_aspect(\"equal\", adjustable=\"box\")\n",
    "    a0.set_xlim(-5, 5)\n",
    "    a0.set_ylim(-5, 5)\n",
    "    _ = a0.set_xlabel(\"pca 1\")\n",
    "    _ = a0.set_ylabel(\"pca 2\")\n",
    "    _ = a0.set_title(\"PCA of embedding space\")\n",
    "\n",
    "    # add a scatter plot one by one for each label\n",
    "    for k in range(10):\n",
    "        mask = all_labels == k\n",
    "        _ = a0.scatter(pca_np_disp[mask, 0], pca_np_disp[mask, 1])\n",
    "    a0.legend(\n",
    "        labels=[ds.features[\"labels\"].int2str(x) for x in range(10)], loc=\"upper right\"\n",
    "    )\n",
    "\n",
    "    # setup subplot for loss\n",
    "    _ = a1.set_ylim(0, 3)\n",
    "    _ = a1.set_xlim(0, max(loss_df[\"epoch\"]))\n",
    "    _ = a1.set_xlabel(\"step\")\n",
    "    _ = a1.set_ylabel(\"loss\")\n",
    "    _ = a1.set_title(\"Training loss\")\n",
    "\n",
    "    # plot loss\n",
    "    loss = loss_df[\"loss\"].copy()\n",
    "    if i + 1 < len(loss):\n",
    "        loss[i + 1 :] = np.nan\n",
    "    _ = a1.plot(loss_df[\"epoch\"], loss, c=\"r\")\n",
    "\n",
    "    # add oulier images\n",
    "    for j, (img, l) in enumerate(df_ood_images):\n",
    "        newax = fig.add_axes([0.85, 0.87 - (j / 11), 0.06, 0.07], anchor=\"NE\", zorder=1)\n",
    "        newax.imshow(img)\n",
    "        newax.axis(\"off\")\n",
    "        newax.set_aspect(\"equal\", \"box\")\n",
    "        newax.set_title(\"Outlier \" + str(j) + f\" ({ds.features['labels'].int2str(l)})\")\n",
    "\n",
    "    plt.savefig(sorted_checkpoint_folder + \"/pca_dyn_procrustes_300_outlow.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a gif from the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import re\n",
    "import imageio\n",
    "\n",
    "# get all images from candidates\n",
    "img_paths = []\n",
    "for sorted_checkpoint_folder in get_sorted_checkpoint_folders():\n",
    "    img_paths += glob.glob(\n",
    "        sorted_checkpoint_folder + \"/pca_dyn_procrustes_300_outlow.png\"\n",
    "    )\n",
    "# sort images by number\n",
    "img_paths = sorted(img_paths, key=lambda x: int(re.findall(r\"\\d+\", x)[0]))\n",
    "\n",
    "\n",
    "with imageio.get_writer(\n",
    "    \"pca_dyn_procrustes_300_outlow.gif\", mode=\"I\", loop=0\n",
    ") as writer:\n",
    "    for filename in img_paths[: 292 // 2]:\n",
    "        image = imageio.imread(filename)\n",
    "        # crop whitespace in image\n",
    "        image = image[10:-100, 110:-10]\n",
    "\n",
    "        writer.append_data(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ds.features[\"labels\"].int2str(x) for x in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
